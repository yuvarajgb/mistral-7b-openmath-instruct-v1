{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c21d427-0bfc-4b22-b903-afc1bbe8d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dill>=0.4.0 multiprocess>=0.70.18 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3abc3d3-2ebf-44ac-b179-d8b9d2519c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install huggingface_hub trl transformers torch datasets bitsandbytes peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085f296f-bc86-4050-b96e-e0fb048b1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import logging\n",
    "from datasets import load_dataset, Dataset, IterableDataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import DPOTrainer\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6194e053-d439-4700-8372-8473df8bbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "# Paste your token here (keep it secure!)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67ab755-258c-40a4-a09b-14237c2877e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be74df378d84a78a7759cd9ead71322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e791424a137a40c18221ed0ed122ec93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c17cd140e64ce098ea24d2e3aa50f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af339470b86b44ceba9f8b10660a4c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63db80322ec14f599836ba44b8abeed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a40bef3ef9640738dbecdf59d7bdcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f842a224577f4a58993503f84b003213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Load model & tokenizer\n",
    "model_id = \"mistral-7b-math/sft/final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cpu\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147137a-c37a-4278-b8fb-53bfb5de3285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e53f86-540a-400c-8a90-0093dc443c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fff391-fb7e-46b0-bff5-4184dffac614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962f3ed4e1ee4d16b197fd89f177133c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model path\n",
    "model_path = \"mistral-7b-math/sft/final\"\n",
    "import os\n",
    "\n",
    "# Load model without quantization (use float16 for memory efficiency)\n",
    "try:\n",
    "    \n",
    "    ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"cpu\",\n",
    "        torch_dtype=torch.float16,  # Half-precision to reduce memory\n",
    "        local_files_only=True,\n",
    "        low_cpu_mem_usage=True  # Optimize memory during loading\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    raise RuntimeError(f\"Failed to load model due to memory constraints: {str(e)}. Try a smaller model or increase available RAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d78ec2-0a4f-4ad6-83b5-4fbbad538d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ef1000-b21f-40bd-a09c-3e5f0992d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel DataFrame columns: ['problem', 'level', 'type', 'solution', 'stage', 'source']\n"
     ]
    }
   ],
   "source": [
    "# Load MATH dataset from Excel\n",
    "excel_file = \"MATH dataset.xlsx\"\n",
    "if not Path(excel_file).is_file():\n",
    "    raise FileNotFoundError(f\"Excel file {excel_file} not found. Please ensure the file exists in the working directory.\")\n",
    "try:\n",
    "    df = pd.read_excel(excel_file)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to read {excel_file}: {str(e)}\")\n",
    "\n",
    "# Print DataFrame columns for debugging\n",
    "print(\"Excel DataFrame columns:\", list(df.columns))\n",
    "\n",
    "# Validate required columns\n",
    "required_columns = [\"problem\", \"solution\"]\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Excel file is missing required columns: {missing_columns}. Found columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7681da85-67e7-4351-93f7-5cdf1cac9c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86fb89848564b99bb91420fedfa4d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size (stage='test'): 5000\n",
      "Processing 100 questions from test set\n",
      "Dataset features: {'problem': Value(dtype='string', id=None), 'level': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'solution': Value(dtype='string', id=None), 'stage': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None)}\n",
      "Sample example: {'problem': 'What is the following value when expressed as a common fraction: $$\\\\frac{1}{2^{1}}+\\\\frac{1}{2^{2}}+\\\\frac{1}{2^{3}}+\\\\cdots + \\\\frac{1}{2^{8}}+\\\\frac{1}{2^{9}}+\\\\frac{1}{2^{10}}?$$', 'level': 'Level 4', 'type': 'Algebra', 'solution': 'This is a finite geometric series with first term $\\\\frac{1}{2}$, common ratio $\\\\frac{1}{2}$ and $10$ terms. Therefore the sum is: $$\\\\frac{\\\\frac{1}{2}\\\\left(1-\\\\frac{1}{2^{10}}\\\\right)}{1-\\\\frac{1}{2}}\\n=\\\\frac{\\\\frac{2^{10}-1}{2^{11}}}{\\\\frac{1}{2}}\\n= \\\\frac{2^{10}-1}{2^{10}}=\\\\boxed{\\\\frac{1023}{1024}}.$$', 'stage': 'test', 'source': 'MATH'}\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to Hugging Face Dataset\n",
    "math_test = Dataset.from_pandas(df)\n",
    "\n",
    "# Filter for stage == \"test\"\n",
    "math_test = math_test.filter(lambda example: example[\"stage\"] == \"test\")\n",
    "test_size = len(math_test)\n",
    "print(f\"Test set size (stage='test'): {test_size}\")\n",
    "\n",
    "# Verify test set size\n",
    "if test_size != 5000:\n",
    "    print(f\"Warning: Expected 5000 rows in test set, got {test_size}\")\n",
    "\n",
    "# Limit to first 100 questions\n",
    "dataset_size = min(100, test_size)\n",
    "math_test = math_test.select(range(dataset_size))\n",
    "print(f\"Processing {dataset_size} questions from test set\")\n",
    "print(\"Dataset features:\", math_test.features)\n",
    "print(\"Sample example:\", math_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8319e973-90e2-4b65-84cb-fe5a472d511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 questions from test set\n",
      "Dataset features: {'problem': Value(dtype='string', id=None), 'level': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'solution': Value(dtype='string', id=None), 'stage': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None)}\n",
      "Sample example: {'problem': 'What is the following value when expressed as a common fraction: $$\\\\frac{1}{2^{1}}+\\\\frac{1}{2^{2}}+\\\\frac{1}{2^{3}}+\\\\cdots + \\\\frac{1}{2^{8}}+\\\\frac{1}{2^{9}}+\\\\frac{1}{2^{10}}?$$', 'level': 'Level 4', 'type': 'Algebra', 'solution': 'This is a finite geometric series with first term $\\\\frac{1}{2}$, common ratio $\\\\frac{1}{2}$ and $10$ terms. Therefore the sum is: $$\\\\frac{\\\\frac{1}{2}\\\\left(1-\\\\frac{1}{2^{10}}\\\\right)}{1-\\\\frac{1}{2}}\\n=\\\\frac{\\\\frac{2^{10}-1}{2^{11}}}{\\\\frac{1}{2}}\\n= \\\\frac{2^{10}-1}{2^{10}}=\\\\boxed{\\\\frac{1023}{1024}}.$$', 'stage': 'test', 'source': 'MATH'}\n"
     ]
    }
   ],
   "source": [
    "# Limit to first 100 questions\n",
    "dataset_size = min(1, test_size)\n",
    "math_test = math_test.select(range(dataset_size))\n",
    "print(f\"Processing {dataset_size} questions from test set\")\n",
    "print(\"Dataset features:\", math_test.features)\n",
    "print(\"Sample example:\", math_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8470396-b614-4783-b951-3d3c6d2332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template for zero-shot Chain-of-Thought\n",
    "def format_prompt(question):\n",
    "    return f\"\"\"Question: {question}\\n\\nSolve the problem step-by-step and provide the final answer in a LaTeX boxed format (\\\\boxed{{}}). Answer:\"\"\"\n",
    "\n",
    "# Initialize predictions list\n",
    "predictions = []\n",
    "\n",
    "# Batch size (conservative for 16GB RAM)\n",
    "batch_size = 1\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba155b5a-4b67-4685-a2b7-f712761baa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 - Type of examples: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Batch 1 - First example: {'problem': 'What is the following value when expressed as a common fraction: $$\\\\frac{1}{2^{1}}+\\\\frac{1}{2^{2}}+\\\\frac{1}{2^{3}}+\\\\cdots + \\\\frac{1}{2^{8}}+\\\\frac{1}{2^{9}}+\\\\frac{1}{2^{10}}?$$', 'level': 'Level 4', 'type': 'Algebra', 'solution': 'This is a finite geometric series with first term $\\\\frac{1}{2}$, common ratio $\\\\frac{1}{2}$ and $10$ terms. Therefore the sum is: $$\\\\frac{\\\\frac{1}{2}\\\\left(1-\\\\frac{1}{2^{10}}\\\\right)}{1-\\\\frac{1}{2}}\\n=\\\\frac{\\\\frac{2^{10}-1}{2^{11}}}{\\\\frac{1}{2}}\\n= \\\\frac{2^{10}-1}{2^{10}}=\\\\boxed{\\\\frac{1023}{1024}}.$$', 'stage': 'test', 'source': 'MATH'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 1/1 [00:49<00:00, 49.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 111/1\n",
      "Evaluation complete. Predictions saved to predictions_Arithmo_MATH_zero_shot_CoT.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process dataset in batches\n",
    "for i in tqdm(range(0, dataset_size, batch_size), desc=\"Processing examples\"):\n",
    "    start = i\n",
    "    end = min(start + batch_size, dataset_size)\n",
    "    \n",
    "    # Select a subset of the dataset\n",
    "    try:\n",
    "        examples = math_test.select(range(start, end))\n",
    "        if not isinstance(examples, Dataset):\n",
    "            raise TypeError(f\"Expected Dataset, got {type(examples)}\")\n",
    "        \n",
    "        # Debug: Print type and content of examples\n",
    "        print(f\"Batch {i//batch_size + 1} - Type of examples: {type(examples)}\")\n",
    "        print(f\"Batch {i//batch_size + 1} - First example: {examples[0]}\")\n",
    "        \n",
    "        # Format prompts\n",
    "        input_text_ft = [format_prompt(example[\"problem\"]) for example in examples]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i//batch_size + 1}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    inputs_ft = tokenizer(\n",
    "        input_text_ft,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(\"cpu\")  # Explicitly keep on CPU\n",
    "    \n",
    "    # Generate outputs\n",
    "    with torch.no_grad():  # Reduce memory usage\n",
    "        try:\n",
    "            generated_ids = ft_model.generate(\n",
    "                **inputs_ft,\n",
    "                max_new_tokens=2048,  # Reduced to save memory\n",
    "                #temperature=0.0,  # Deterministic\n",
    "                do_sample=False,  # Greedy decoding\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Generation failed for batch {i//batch_size + 1}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Decode outputs\n",
    "    output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Store predictions\n",
    "    for j in range(len(output)):\n",
    "        predictions.append({\n",
    "            \"question\": examples[j][\"problem\"],\n",
    "            \"ground_truth\": examples[j][\"solution\"],\n",
    "            \"prediction\": output[j]\n",
    "        })\n",
    "    \n",
    "    count += len(output)\n",
    "    print(f\"Processed: {count}/{dataset_size}\")\n",
    "    \n",
    "    # Save predictions incrementally to avoid memory issues\n",
    "    if count % 50 == 0 or count == dataset_size:\n",
    "        with open('predictions_Arithmo_MATH_zero_shot_CoT.json', 'w') as f:\n",
    "            json.dump(predictions, f, indent=1)\n",
    "\n",
    "# Final save\n",
    "with open('predictions_Arithmo_MATH_zero_shot_CoT.json', 'w') as f:\n",
    "    json.dump(predictions, f, indent=1)\n",
    "\n",
    "print(\"Evaluation complete. Predictions saved to predictions_Arithmo_MATH_zero_shot_CoT.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef6024-f3fd-43ab-b2be-e75e1d311348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458471f-30c6-4275-ace8-ffedb43c1960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b774435-1895-439a-b3f6-1981f1ad3d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Instances: 111, Correct Count: 0, Accuracy (Correct Count/Total Instances): 0.0\n",
      "\n",
      "Out of 111 instances, couldn't find answer for 111 instances.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import json\n",
    "\n",
    "incorrect_prediction_records = []\n",
    "\n",
    "def _fix_fracs(string):\n",
    "    substrs = string.split(\"\\\\frac\")\n",
    "    new_str = substrs[0]\n",
    "    if len(substrs) > 1:\n",
    "        substrs = substrs[1:]\n",
    "        for substr in substrs:\n",
    "            new_str += \"\\\\frac\"\n",
    "            if substr[0] == \"{\":\n",
    "                new_str += substr\n",
    "            else:\n",
    "                try:\n",
    "                    assert len(substr) >= 2\n",
    "                except:\n",
    "                    return string\n",
    "                a = substr[0]\n",
    "                b = substr[1]\n",
    "                if b != \"{\":\n",
    "                    if len(substr) > 2:\n",
    "                        post_substr = substr[2:]\n",
    "                        new_str += \"{\" + a + \"}{\" + b + \"}\" + post_substr\n",
    "                    else:\n",
    "                        new_str += \"{\" + a + \"}{\" + b + \"}\"\n",
    "                else:\n",
    "                    if len(substr) > 2:\n",
    "                        post_substr = substr[2:]\n",
    "                        new_str += \"{\" + a + \"}\" + b + post_substr\n",
    "                    else:\n",
    "                        new_str += \"{\" + a + \"}\" + b\n",
    "    string = new_str\n",
    "    return string\n",
    "\n",
    "\n",
    "def _fix_a_slash_b(string):\n",
    "    if len(string.split(\"/\")) != 2:\n",
    "        return string\n",
    "    a = string.split(\"/\")[0]\n",
    "    b = string.split(\"/\")[1]\n",
    "    try:\n",
    "        a = int(a)\n",
    "        b = int(b)\n",
    "        assert string == \"{}/{}\".format(a, b)\n",
    "        new_string = \"\\\\frac{\" + str(a) + \"}{\" + str(b) + \"}\"\n",
    "        return new_string\n",
    "    except:\n",
    "        return string\n",
    "\n",
    "\n",
    "def _remove_right_units(string):\n",
    "    # \"\\\\text{ \" only ever occurs (at least in the val set) when describing units\n",
    "    if \"\\\\text{ \" in string:\n",
    "        splits = string.split(\"\\\\text{ \")\n",
    "        assert len(splits) == 2\n",
    "        return splits[0]\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "\n",
    "def _fix_sqrt(string):\n",
    "    if \"\\\\sqrt\" not in string:\n",
    "        return string\n",
    "    splits = string.split(\"\\\\sqrt\")\n",
    "    new_string = splits[0]\n",
    "    for split in splits[1:]:\n",
    "        if split[0] != \"{\":\n",
    "            a = split[0]\n",
    "            new_substr = \"\\\\sqrt{\" + a + \"}\" + split[1:]\n",
    "        else:\n",
    "            new_substr = \"\\\\sqrt\" + split\n",
    "        new_string += new_substr\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def _strip_string(string):\n",
    "    # linebreaks\n",
    "    string = string.replace(\"\\n\", \"\")\n",
    "    # print(string)\n",
    "\n",
    "    # remove inverse spaces\n",
    "    string = string.replace(\"\\\\!\", \"\")\n",
    "    # print(string)\n",
    "\n",
    "    # replace \\\\ with \\\n",
    "    string = string.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "    # print(string)\n",
    "\n",
    "    # replace tfrac and dfrac with frac\n",
    "    string = string.replace(\"tfrac\", \"frac\")\n",
    "    string = string.replace(\"dfrac\", \"frac\")\n",
    "    # print(string)\n",
    "\n",
    "    # remove \\left and \\right\n",
    "    string = string.replace(\"\\\\left\", \"\")\n",
    "    string = string.replace(\"\\\\right\", \"\")\n",
    "    # print(string)\n",
    "\n",
    "    # Remove circ (degrees)\n",
    "    string = string.replace(\"^{\\\\circ}\", \"\")\n",
    "    string = string.replace(\"^\\\\circ\", \"\")\n",
    "\n",
    "    # remove dollar signs\n",
    "    string = string.replace(\"\\\\$\", \"\")\n",
    "\n",
    "    # remove units (on the right)\n",
    "    string = _remove_right_units(string)\n",
    "\n",
    "    # remove percentage\n",
    "    string = string.replace(\"\\\\%\", \"\")\n",
    "    string = string.replace(\"\\%\", \"\")\n",
    "\n",
    "    # \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string\n",
    "    string = string.replace(\" .\", \" 0.\")\n",
    "    string = string.replace(\"{.\", \"{0.\")\n",
    "    # if empty, return empty string\n",
    "    if len(string) == 0:\n",
    "        return string\n",
    "    if string[0] == \".\":\n",
    "        string = \"0\" + string\n",
    "\n",
    "    # to consider: get rid of e.g. \"k = \" or \"q = \" at beginning\n",
    "    if len(string.split(\"=\")) == 2:\n",
    "        if len(string.split(\"=\")[0]) <= 2:\n",
    "            string = string.split(\"=\")[1]\n",
    "\n",
    "    # fix sqrt3 --> sqrt{3}\n",
    "    string = _fix_sqrt(string)\n",
    "\n",
    "    # remove spaces\n",
    "    string = string.replace(\" \", \"\")\n",
    "\n",
    "    # \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}\n",
    "    string = _fix_fracs(string)\n",
    "\n",
    "    # manually change 0.5 --> \\frac{1}{2}\n",
    "    if string == \"0.5\":\n",
    "        string = \"\\\\frac{1}{2}\"\n",
    "\n",
    "    # NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y\n",
    "    string = _fix_a_slash_b(string)\n",
    "\n",
    "    return string\n",
    "\n",
    "\n",
    "def is_equiv(str1, str2, verbose=False):\n",
    "    if str1 is None and str2 is None:\n",
    "        print(\"WARNING: Both None\")\n",
    "        return True\n",
    "    if str1 is None or str2 is None:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        ss1 = _strip_string(str1)\n",
    "        ss2 = _strip_string(str2)\n",
    "        if verbose:\n",
    "            print(ss1, ss2)\n",
    "        return ss1 == ss2\n",
    "    except:\n",
    "        return str1 == str2\n",
    "\n",
    "\n",
    "def last_boxed_only_string(string):\n",
    "    idx = string.rfind(\"\\\\boxed\")\n",
    "    if idx < 0:\n",
    "        idx = string.rfind(\"\\\\fbox\")\n",
    "        if idx < 0:\n",
    "            return None\n",
    "\n",
    "    i = idx\n",
    "    right_brace_idx = None\n",
    "    num_left_braces_open = 0\n",
    "    while i < len(string):\n",
    "        if string[i] == \"{\":\n",
    "            num_left_braces_open += 1\n",
    "        if string[i] == \"}\":\n",
    "            num_left_braces_open -= 1\n",
    "            if num_left_braces_open == 0:\n",
    "                right_brace_idx = i\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    if right_brace_idx == None:\n",
    "        retval = None\n",
    "    else:\n",
    "        retval = string[idx:right_brace_idx + 1]\n",
    "\n",
    "    return retval\n",
    "\n",
    "def remove_boxed(s):\n",
    "    left = \"\\\\boxed{\"\n",
    "    try:\n",
    "        assert s[:len(left)] == left\n",
    "        assert s[-1] == \"}\"\n",
    "        return s[len(left):-1]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_result(ground_truth_solution, generated_text, question, pos):\n",
    "    answer = remove_boxed(last_boxed_only_string(ground_truth_solution))\n",
    "    if \"The answer is:\" in generated_text:\n",
    "        predicted_answer = generated_text.rsplit(\"The answer is:\")[-1].strip()\n",
    "    elif \"The answer is \" in generated_text:\n",
    "        predicted_answer = generated_text.rsplit(\"The answer is \")[-1].strip()\n",
    "    else: # TODO: This is most likely because we stopped generation in between. There are very rare cases when model doesn't generate \"The answer is\" format.\n",
    "        predicted_answer = \"\"  # answer is missing\n",
    "\n",
    "    try:\n",
    "        equiv = is_equiv(predicted_answer, answer)\n",
    "    except:\n",
    "        equiv = False\n",
    "    if not equiv:\n",
    "        incorrect_prediction_record = {\n",
    "            \"Record#\": pos+1,\n",
    "            \"question\": question,\n",
    "            \"correct_answer\": answer,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"correct_completion\": ground_truth_solution,\n",
    "            \"predicted_completion\": generated_text,\n",
    "        }\n",
    "        incorrect_prediction_records.append(incorrect_prediction_record)\n",
    "    return equiv, predicted_answer == \"\"\n",
    "\n",
    "\n",
    "correct, total, missing_answer_count = 0, 0, 0\n",
    "file_path = \"predictions_Arithmo_MATH_zero_shot_CoT.json\"\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for i, d in enumerate(data):\n",
    "        question = d[\"question\"]\n",
    "        ground_truth_gen = d[\"ground_truth\"]\n",
    "        predicted_gen = d[\"prediction\"]\n",
    "        is_correct, is_answer_missing = get_result(ground_truth_gen, predicted_gen, question, i)\n",
    "        correct += is_correct\n",
    "        total += 1\n",
    "        missing_answer_count += is_answer_missing\n",
    "\n",
    "print(f\"\\nTotal Instances: {total}, Correct Count: {correct}, Accuracy (Correct Count/Total Instances): {correct/total}\")\n",
    "print(f\"\\nOut of {total} instances, couldn't find answer for {missing_answer_count} instances.\")\n",
    "\n",
    "with open('mistral-7b-math/incorrect_predictions_Arithmo_math_zero_shot_CoT.json', 'w') as f:\n",
    "        json.dump(incorrect_prediction_records, f, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ae823-58a8-4e3c-ab68-32329b7dde1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
